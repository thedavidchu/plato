type: invertinggradients

attack_type: optimization # analytic, equation solver
label_strategy: bias-corrected # Only in effect if the user does not provide labels
# Label strategy options are 'iDLG', 'analytic', 'yin', 'wainakh-simple', 'wainakh-whitebox', 'random', 'exhaustive'
text_strategy: run-embedding # options: run-embedding
token_recovery: from-labels

objective:
  type: cosine-similarity
  scale: 1.0 # need to have a much smaller scale like 0.0001 for euclidean objectives
  task_regularization: 0.0

restarts:
  num_trials: 1
  scoring: "cosine-similarity"

init: "patterned-4-randn"
normalize_gradients: False



optim:
  optimizer: Adam
  signed: "soft"
  step_size: 0.1
  boxed: True
  max_iterations: 24_000
  step_size_decay: cosine-decay
  langevin_noise: 0.0
  warmup: 50
  grad_clip:

  callback: 100 # Print objective value every callback many iterations

augmentations:

differentiable_augmentations: False

regularization:
  total_variation:
    scale: 0.2
    inner_exp: 2
    outer_exp: 0.5
    double_opponents: True
  features:
    scale: .0
  deep_inversion:
    scale: .0
impl:
  dtype: float
  mixed_precision: False
  JIT: # bembel with care
